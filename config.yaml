autoencoder:
  class: VQModel
  model:
    attn_resolutions:
    - 32
    ch: 64
    channel_mult:
    - 2
    - 4
    - 8
    - 16
    embed_dim: 32
    in_channels: 128
    n_embed: 2048
    num_res_blocks: 3
    out_channels: 2
    resolution: 256
    z_channels: 4
  train:
    batch_size: 16
    checkpoint_every: 1000
    data_path: ../data/lakh_giant_midi_prmat2c_8bin_lmdb
    gradient_accumulation_steps: 2
    gradient_clip_val: 1.0
    learning_rate: 0.00002
    logger_kwargs:
      entity: rainbow_tensor
      id:
      log_model: all
      project: music_diffusion
    lr_warmup_steps: 500
    mixed_precision: fp16
    num_epochs: 50
    resume: false
    save_dir: ./models
    save_name: autoencoder
music_diffusion:
  class: MusicDiffusion
  model:
    blocks:
    - 6
    - 14
    - 6
    c_cond: 0
    c_hidden:
    - 512
    - 1024
    - 1024
    c_in: 4
    c_out: 4
    c_r: 64
    dropout: 0.1
    kernel_size: 3
    level_config:
    - CT
    - CTA
    - CTA
    n_class_cond: 6
    nhead:
    - -1
    - 16
    - 16
    patch_size: 2
  train:
    batch_size: 4
    checkpoint_every: 1000
    data_path: ../data/lakh_reduced_prmat2c_8bin_pt2_lmdb
    gradient_accumulation_steps: 2
    gradient_clip_val: 1.0
    learning_rate: 0.0001
    logger_kwargs:
      entity: rainbow_tensor
      id: null
      log_model: all
      project: music_diffusion
    lr_warmup_steps: 500
    mixed_precision: fp16
    num_epochs: 50
    resume: false
    save_dir: ./models
    save_name: music_diffusion
